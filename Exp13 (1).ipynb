{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp13.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Aim:** \n",
        "Programs on convolutional neural network to classify images from any standard dataset\n",
        "in the public domain.\n",
        "\n",
        "**Short Notes:**\n",
        "A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. \n",
        "\n",
        "A ConvNet is able to successfully capture the Spatial and Temporal dependencies in an image through the application of relevant filters. The architecture performs a better fitting to the image dataset due to the reduction in the number of parameters involved and reusability of weights. In other words, the network can be trained to understand the sophistication of the image better.\n",
        "\n",
        "In this experiment, we will classify handwrittten digits images. MNIST (Modified National Institute of Standards and Technology) is a well-known dataset composed of images that are handwritten digits (0-9), split into a training set of 50,000 images and a test set of 10,000 where each image is of 28 x 28 pixels in width and height.\n",
        "\n"
      ],
      "metadata": {
        "id": "x2w1XQriDEDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithm:**\n",
        "\n",
        "The basic steps to build an image classification model using a neural network are:\n",
        "\n",
        "1. Flatten the input image dimensions to 1D (width pixels x height pixels)\n",
        "2. Normalize the image pixel values (divide by 255)\n",
        "3. One-Hot Encode the categorical column\n",
        "4. Build a model architecture (Sequential) with Dense layers\n",
        "5. Train the model and make predictions"
      ],
      "metadata": {
        "id": "KbTIJGV3Hb5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.utils import np_utils"
      ],
      "metadata": {
        "id": "0XJHh6zOEYGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "Dh_XJFrOFSQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the input vector from the 28x28 pixels\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalizing the data to help with the training\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "metadata": {
        "id": "LSuLJd3fH3ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHF9teKkGQgb",
        "outputId": "7897ef93-086f-4dd8-8cda-c822d3adb855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before one-hot encoding:  (60000,)\n",
            "Shape after one-hot encoding:  (60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='relu'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# training the model for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GGzKVAjH_u_",
        "outputId": "5d1a14d9-43ee-4534-8fc4-8120f40e3817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 39s 81ms/step - loss: 0.1864 - accuracy: 0.9452 - val_loss: 0.0812 - val_accuracy: 0.9755\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.0567 - accuracy: 0.9830 - val_loss: 0.0536 - val_accuracy: 0.9825\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.0341 - accuracy: 0.9901 - val_loss: 0.0510 - val_accuracy: 0.9831\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0483 - val_accuracy: 0.9845\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0568 - val_accuracy: 0.9828\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.0531 - val_accuracy: 0.9833\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 37s 80ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0539 - val_accuracy: 0.9841\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 37s 80ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0734 - val_accuracy: 0.9811\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 37s 80ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0672 - val_accuracy: 0.9826\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 37s 80ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0646 - val_accuracy: 0.9846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4521582090>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "swJ30X1ZIbUP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}